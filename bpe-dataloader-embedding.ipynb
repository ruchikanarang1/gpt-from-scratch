{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9898922,"sourceType":"datasetVersion","datasetId":6080588}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"a346f72d","cell_type":"code","source":"! pip3 install tiktoken","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T08:55:29.453062Z","iopub.execute_input":"2025-10-16T08:55:29.453305Z","iopub.status.idle":"2025-10-16T08:55:34.924642Z","shell.execute_reply.started":"2025-10-16T08:55:29.453271Z","shell.execute_reply":"2025-10-16T08:55:34.923458Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2025.9.18)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.5)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.8.3)\n","output_type":"stream"}],"execution_count":1},{"id":"5d417ace","cell_type":"code","source":"import importlib\nimport tiktoken\ntokenizer = tiktoken.get_encoding(\"gpt2\")\ntext = (\n    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n     \"of someunknownPlace.\"\n)\n\nintegers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n\nprint(integers)\n\nstrings = tokenizer.decode(integers)\n\nprint(strings)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T08:55:34.925907Z","iopub.execute_input":"2025-10-16T08:55:34.927197Z","iopub.status.idle":"2025-10-16T08:55:38.409149Z","shell.execute_reply.started":"2025-10-16T08:55:34.927154Z","shell.execute_reply":"2025-10-16T08:55:38.408229Z"}},"outputs":[{"name":"stdout","text":"[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\nHello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n","output_type":"stream"}],"execution_count":2},{"id":"c57abdb1","cell_type":"markdown","source":"notice the difference between the tokenizer between simple vocabulary based encoder and a byte pair encoder.\n#simple tkenizer gives 4690\n","metadata":{}},{"id":"3539031b","cell_type":"code","source":"with open(\"/kaggle/input/the-verdict-txt/the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n    raw_text = f.read()\n\nenc_text = tokenizer.encode(raw_text)\nprint(len(enc_text))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T08:55:38.411499Z","iopub.execute_input":"2025-10-16T08:55:38.411749Z","iopub.status.idle":"2025-10-16T08:55:38.435728Z","shell.execute_reply.started":"2025-10-16T08:55:38.411730Z","shell.execute_reply":"2025-10-16T08:55:38.434701Z"}},"outputs":[{"name":"stdout","text":"5145\n","output_type":"stream"}],"execution_count":3},{"id":"4d2ca0a5","cell_type":"markdown","source":"once the encoding is done we will implement a sliding window using context length to create input output pairs, we know that gpt works on next word prediction so creating input output pairs and looking at the next word to be predicted gives us a ground truth to use to evaluate and train our model.\n\nstride can be different , for now we focus on context length.","metadata":{}},{"id":"72382f9e","cell_type":"code","source":"enc_sample = enc_text[50:]\ncontext_size = 4\n\nx = enc_sample[:context_size]\ny = enc_sample[1:context_size+1]\n\nprint(f\"x: {x}\")\nprint(f\"y:      {y}\")\nfor i in range(1, context_size+1):\n    context = enc_sample[:i]\n    desired = enc_sample[i]\n\n    print(context, \"---->\", desired)\n\nfor i in range(1, context_size+1):\n    context = enc_sample[:i]\n    desired = enc_sample[i]\n\n    print(tokenizer.decode(context), \"---->\", tokenizer.decode([desired]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T08:55:38.436511Z","iopub.execute_input":"2025-10-16T08:55:38.436849Z","iopub.status.idle":"2025-10-16T08:55:38.444318Z","shell.execute_reply.started":"2025-10-16T08:55:38.436825Z","shell.execute_reply":"2025-10-16T08:55:38.443293Z"}},"outputs":[{"name":"stdout","text":"x: [290, 4920, 2241, 287]\ny:      [4920, 2241, 287, 257]\n[290] ----> 4920\n[290, 4920] ----> 2241\n[290, 4920, 2241] ----> 287\n[290, 4920, 2241, 287] ----> 257\n and ---->  established\n and established ---->  himself\n and established himself ---->  in\n and established himself in ---->  a\n","output_type":"stream"}],"execution_count":4},{"id":"ba46000b","cell_type":"markdown","source":"DATALOADER","metadata":{}},{"id":"a70c028a","cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\n\n\nclass GPTDatasetV1(Dataset):\n    def __init__(self, txt, tokenizer, max_length, stride):\n        self.input_ids = []\n        self.target_ids = []\n\n        # Tokenize the entire text\n        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n\n        # Use a sliding window to chunk the book into overlapping sequences of max_length\n        for i in range(0, len(token_ids) - max_length, stride):\n            input_chunk = token_ids[i:i + max_length]\n            target_chunk = token_ids[i + 1: i + max_length + 1]\n            self.input_ids.append(torch.tensor(input_chunk))\n            self.target_ids.append(torch.tensor(target_chunk))\n\n    def __len__(self):\n        return len(self.input_ids)\n\n    def __getitem__(self, idx):\n        return self.input_ids[idx], self.target_ids[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T08:55:38.445355Z","iopub.execute_input":"2025-10-16T08:55:38.445670Z","iopub.status.idle":"2025-10-16T08:55:43.139609Z","shell.execute_reply.started":"2025-10-16T08:55:38.445648Z","shell.execute_reply":"2025-10-16T08:55:43.138727Z"}},"outputs":[],"execution_count":5},{"id":"416f4801","cell_type":"code","source":"def create_dataloader_v1(txt, batch_size=4, max_length=256, \n                         stride=128, shuffle=True, drop_last=True,\n                         num_workers=0):\n\n    # Initialize the tokenizer\n    tokenizer = tiktoken.get_encoding(\"gpt2\")\n\n    # Create dataset\n    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n\n    # Create dataloader\n    dataloader = DataLoader(\n        dataset,\n        batch_size=batch_size,\n        shuffle=shuffle,\n        drop_last=drop_last,\n        num_workers=num_workers\n    )\n\n    return dataloader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T08:55:43.140437Z","iopub.execute_input":"2025-10-16T08:55:43.140880Z","iopub.status.idle":"2025-10-16T08:55:43.146525Z","shell.execute_reply.started":"2025-10-16T08:55:43.140857Z","shell.execute_reply":"2025-10-16T08:55:43.145725Z"}},"outputs":[],"execution_count":6},{"id":"e25755eb","cell_type":"code","source":"with open(\"/kaggle/input/the-verdict-txt/the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n    raw_text = f.read()\n\nimport torch\nprint(\"PyTorch version:\", torch.__version__)\ndataloader = create_dataloader_v1(\n    raw_text, batch_size=1, max_length=4, stride=1, shuffle=False\n)\n\ndata_iter = iter(dataloader)\nfirst_batch = next(data_iter)\nprint(first_batch)\n\nsecond_batch = next(data_iter)\nprint(second_batch)\n\ndataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n\ndata_iter = iter(dataloader)\ninputs, targets = next(data_iter)\nprint(\"Inputs:\\n\", inputs)\nprint(\"\\nTargets:\\n\", targets)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T09:00:47.718056Z","iopub.execute_input":"2025-10-16T09:00:47.718431Z","iopub.status.idle":"2025-10-16T09:00:47.897263Z","shell.execute_reply.started":"2025-10-16T09:00:47.718404Z","shell.execute_reply":"2025-10-16T09:00:47.896340Z"}},"outputs":[{"name":"stdout","text":"PyTorch version: 2.6.0+cu124\n[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n[tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]\nInputs:\n tensor([[   40,   367,  2885,  1464],\n        [ 1807,  3619,   402,   271],\n        [10899,  2138,   257,  7026],\n        [15632,   438,  2016,   257],\n        [  922,  5891,  1576,   438],\n        [  568,   340,   373,   645],\n        [ 1049,  5975,   284,   502],\n        [  284,  3285,   326,    11]])\n\nTargets:\n tensor([[  367,  2885,  1464,  1807],\n        [ 3619,   402,   271, 10899],\n        [ 2138,   257,  7026, 15632],\n        [  438,  2016,   257,   922],\n        [ 5891,  1576,   438,   568],\n        [  340,   373,   645,  1049],\n        [ 5975,   284,   502,   284],\n        [ 3285,   326,    11,   287]])\n","output_type":"stream"}],"execution_count":8},{"id":"eaf192e3","cell_type":"code","source":"vocab_size = 50257\noutput_dim = 256\n\ntoken_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\nprint(token_embedding_layer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T09:10:24.683804Z","iopub.execute_input":"2025-10-16T09:10:24.685538Z","iopub.status.idle":"2025-10-16T09:10:24.833538Z","shell.execute_reply.started":"2025-10-16T09:10:24.685501Z","shell.execute_reply":"2025-10-16T09:10:24.832664Z"}},"outputs":[{"name":"stdout","text":"Embedding(50257, 256)\n","output_type":"stream"}],"execution_count":9},{"id":"25d060db-307f-406d-b2c5-9f1e165ecb34","cell_type":"code","source":"max_length = 4\ndataloader = create_dataloader_v1(\n    raw_text, batch_size=8, max_length=max_length,\n    stride=max_length, shuffle=False\n)\ndata_iter = iter(dataloader)\ninputs, targets = next(data_iter)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T09:10:37.677015Z","iopub.execute_input":"2025-10-16T09:10:37.677328Z","iopub.status.idle":"2025-10-16T09:10:37.716733Z","shell.execute_reply.started":"2025-10-16T09:10:37.677306Z","shell.execute_reply":"2025-10-16T09:10:37.715839Z"}},"outputs":[],"execution_count":10},{"id":"6e1e0642-db6f-4ae9-a8e2-1fea051ab446","cell_type":"code","source":"print(\"Token IDs:\\n\", inputs)\nprint(\"\\nInputs shape:\\n\", inputs.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T09:10:41.226454Z","iopub.execute_input":"2025-10-16T09:10:41.226811Z","iopub.status.idle":"2025-10-16T09:10:41.235383Z","shell.execute_reply.started":"2025-10-16T09:10:41.226783Z","shell.execute_reply":"2025-10-16T09:10:41.234286Z"}},"outputs":[{"name":"stdout","text":"Token IDs:\n tensor([[   40,   367,  2885,  1464],\n        [ 1807,  3619,   402,   271],\n        [10899,  2138,   257,  7026],\n        [15632,   438,  2016,   257],\n        [  922,  5891,  1576,   438],\n        [  568,   340,   373,   645],\n        [ 1049,  5975,   284,   502],\n        [  284,  3285,   326,    11]])\n\nInputs shape:\n torch.Size([8, 4])\n","output_type":"stream"}],"execution_count":11},{"id":"2855169e-6fab-4eaf-bf0a-77d4ae3469ea","cell_type":"markdown","source":"\n*the token ID tensor is 8x4-dimensional, meaning that the data batchconsists of 8 text samples with 4 tokens each.*\n","metadata":{}},{"id":"67c6e184-4480-40e6-ab92-00dc7c83cb67","cell_type":"code","source":"token_embeddings = token_embedding_layer(inputs)\nprint(token_embeddings.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T09:10:49.809125Z","iopub.execute_input":"2025-10-16T09:10:49.809417Z","iopub.status.idle":"2025-10-16T09:10:49.825321Z","shell.execute_reply.started":"2025-10-16T09:10:49.809396Z","shell.execute_reply":"2025-10-16T09:10:49.824325Z"}},"outputs":[{"name":"stdout","text":"torch.Size([8, 4, 256])\n","output_type":"stream"}],"execution_count":12},{"id":"ee276a9a-1186-48a9-8fa7-bbac02812d44","cell_type":"markdown","source":"\n*based on the 8x4x256-dimensional tensor output, each token ID is nowembedded as a 256-dimensional vector.*\n","metadata":{}},{"id":"735edc80-4b96-4003-88bc-93feae2979a6","cell_type":"markdown","source":"\n*For a GPT model's absolute embedding approach, we just need to create anotherembedding layer that has the same dimension as the token_embedding_layer:*\n","metadata":{}},{"id":"b325fbdb-6160-4665-bed4-8711d5b65399","cell_type":"code","source":"context_length = max_length\npos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\npos_embeddings = pos_embedding_layer(torch.arange(max_length))\nprint(pos_embeddings.shape)\ninput_embeddings = token_embeddings + pos_embeddings\nprint(input_embeddings.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T09:11:20.129737Z","iopub.execute_input":"2025-10-16T09:11:20.130065Z","iopub.status.idle":"2025-10-16T09:11:20.181295Z","shell.execute_reply.started":"2025-10-16T09:11:20.130040Z","shell.execute_reply":"2025-10-16T09:11:20.180452Z"}},"outputs":[{"name":"stdout","text":"torch.Size([4, 256])\ntorch.Size([8, 4, 256])\n","output_type":"stream"}],"execution_count":13}]}